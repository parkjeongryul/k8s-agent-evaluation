#!/usr/bin/env python3
"""
ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ íë¦„ ë°ëª¨ ë° ëª¨ë‹ˆí„°ë§
"""
import os
import time
import asyncio
from datetime import datetime

# ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ì¶”ì ì„ ìœ„í•œ Mock
class NetworkTracker:
    def __init__(self):
        self.requests = []
    
    def log_request(self, method: str, url: str, payload_size: int = 0):
        """ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ë¡œê¹…"""
        self.requests.append({
            "timestamp": datetime.now(),
            "method": method,
            "url": url,
            "payload_size": payload_size,
            "type": self._classify_request(url)
        })
        print(f"ğŸ“¡ {method} {url} ({payload_size} bytes)")
    
    def _classify_request(self, url: str) -> str:
        """ìš”ì²­ íƒ€ì… ë¶„ë¥˜"""
        if "internal-llm" in url or "10.0.1" in url:
            return "internal_llm"
        elif "smith.langchain.com" in url:
            return "external_blocked"
        elif "api.openai.com" in url:
            return "external_blocked"
        else:
            return "unknown"
    
    def print_summary(self):
        """íŠ¸ë˜í”½ ìš”ì•½ ì¶œë ¥"""
        print(f"\nğŸ“Š ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ ìš”ì•½:")
        print(f"{'='*50}")
        
        internal_count = len([r for r in self.requests if r["type"] == "internal_llm"])
        blocked_count = len([r for r in self.requests if r["type"] == "external_blocked"])
        total_payload = sum(r["payload_size"] for r in self.requests)
        
        print(f"âœ… ì‚¬ë‚´ LLM ìš”ì²­: {internal_count}ê°œ")
        print(f"ğŸš« ì°¨ë‹¨ëœ ì™¸ë¶€ ìš”ì²­: {blocked_count}ê°œ")
        print(f"ğŸ“¦ ì´ ì „ì†¡ëŸ‰: {total_payload:,} bytes")
        print(f"â±ï¸  ì‹¤í–‰ ì‹œê°„: {len(self.requests)} requests")
        
        if self.requests:
            print(f"\nğŸ“‹ ìš”ì²­ ìƒì„¸:")
            for i, req in enumerate(self.requests, 1):
                status = "âœ…" if req["type"] == "internal_llm" else "ğŸš«"
                print(f"  {i}. {status} {req['method']} {req['url'][:50]}...")


async def simulate_evaluation_flow():
    """í‰ê°€ ì‹œìŠ¤í…œ ì‹¤í–‰ íë¦„ ì‹œë®¬ë ˆì´ì…˜"""
    tracker = NetworkTracker()
    
    print("ğŸš€ K8s Agent í‰ê°€ ì‹œìŠ¤í…œ íŠ¸ë˜í”½ íë¦„ ì‹œë®¬ë ˆì´ì…˜")
    print("="*60)
    
    # Phase 1: ì´ˆê¸°í™”
    print(f"\nğŸ”§ Phase 1: ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
    print(f"   ğŸ“ Few-shot YAML íŒŒì¼ ë¡œë“œ... (ë¡œì»¬ íŒŒì¼ ì‹œìŠ¤í…œ)")
    await asyncio.sleep(0.5)
    
    print(f"   ğŸ”’ ì™¸ë¶€ ì „ì†¡ ì°¨ë‹¨ í™•ì¸...")
    # ì™¸ë¶€ ìš”ì²­ ì°¨ë‹¨ ì‹œë®¬ë ˆì´ì…˜
    try:
        # ì‹¤ì œë¡œëŠ” ìš”ì²­í•˜ì§€ ì•Šì§€ë§Œ ì°¨ë‹¨ë¨ì„ ë³´ì—¬ì¤Œ
        print(f"      ğŸš« smith.langchain.com ì ‘ê·¼ ì°¨ë‹¨ë¨")
        print(f"      ğŸš« api.openai.com ì ‘ê·¼ ì°¨ë‹¨ë¨")
    except:
        pass
    
    print(f"   ğŸ§ª ì‚¬ë‚´ LLM ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸...")
    tracker.log_request("POST", "http://internal-llm.company.com:8000/v1/chat/completions", 150)
    await asyncio.sleep(1.0)
    
    # Phase 2: í‰ê°€ ì‹¤í–‰
    print(f"\nğŸ“Š Phase 2: Agent í‰ê°€ ì‹¤í–‰")
    test_cases = [
        "OOMKilled ì˜¤ë¥˜ ë¶„ì„",
        "ê²€ìƒ‰ ì„±ëŠ¥ ìµœì í™”", 
        "Rolling Update ì„¤ì •",
        "HPA êµ¬ì„±",
        "ImagePullBackOff í•´ê²°"
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\n   ğŸ“ í…ŒìŠ¤íŠ¸ {i}: {test_case}")
        print(f"      ğŸ¤– Mock Agent ì‘ë‹µ ìƒì„± (ë¡œì»¬)")
        await asyncio.sleep(0.3)
        
        print(f"      ğŸ¯ Few-shot ì˜ˆì œ ì„ íƒ (ë¡œì»¬ YAML)")
        await asyncio.sleep(0.2)
        
        print(f"      ğŸ“ í‰ê°€ í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ë¡œì»¬)")
        
        # ì‹¤ì œ ì‚¬ë‚´ LLM í˜¸ì¶œ ì‹œë®¬ë ˆì´ì…˜
        prompt_size = 1500 + len(test_case) * 10  # í”„ë¡¬í”„íŠ¸ í¬ê¸° ì¶”ì •
        print(f"      ğŸ”„ ì‚¬ë‚´ LLM í‰ê°€ ìš”ì²­...")
        tracker.log_request("POST", "http://internal-llm.company.com:8000/v1/chat/completions", prompt_size)
        await asyncio.sleep(2.0)  # LLM ì‘ë‹µ ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
        
        print(f"      ğŸ’¾ í‰ê°€ ê²°ê³¼ ë¡œì»¬ ì €ì¥")
        await asyncio.sleep(0.1)
    
    # Phase 3: ê²°ê³¼ ì €ì¥
    print(f"\nğŸ’¾ Phase 3: ê²°ê³¼ ì €ì¥ ë° ì •ë¦¬")
    print(f"   ğŸ“„ JSON íŒŒì¼ ì €ì¥ (ë¡œì»¬)")
    print(f"   ğŸ“Š ë©”íŠ¸ë¦­ ê³„ì‚° (ë¡œì»¬)")
    
    # íŠ¸ë˜í”½ ìš”ì•½
    tracker.print_summary()
    
    print(f"\nğŸ” ë³´ì•ˆ í™•ì¸:")
    print(f"   âœ… ëª¨ë“  ë°ì´í„°ê°€ ì‚¬ë‚´ ë„¤íŠ¸ì›Œí¬ì—ì„œë§Œ ì²˜ë¦¬ë¨")
    print(f"   âœ… ì™¸ë¶€ ì„œë²„ë¡œ ì „ì†¡ëœ ë°ì´í„°: 0 bytes")
    print(f"   âœ… ì‚¬ë‚´ LLMì„œë²„ ì™¸ ë‹¤ë¥¸ ì—°ê²° ì—†ìŒ")


def show_actual_flow():
    """ì‹¤ì œ ì½”ë“œì—ì„œì˜ íŠ¸ë˜í”½ íë¦„"""
    print(f"\nğŸ“‹ ì‹¤ì œ ì½”ë“œì—ì„œì˜ ë„¤íŠ¸ì›Œí¬ íë¦„:")
    print(f"{'='*50}")
    
    flow_steps = [
        ("ì‹œì‘", "internal_llm_config.py ì‹¤í–‰"),
        ("í™˜ê²½ë³€ìˆ˜", "OPENAI_BASE_URL í™•ì¸ â†’ ì‚¬ë‚´ ì„œë²„"),
        ("ì°¨ë‹¨", "LANGCHAIN_* í™˜ê²½ë³€ìˆ˜ ì œê±° â†’ ì™¸ë¶€ ì „ì†¡ ì°¨ë‹¨"),
        ("Few-shot", "YAML íŒŒì¼ ë¡œë“œ â†’ ë¡œì»¬ íŒŒì¼ì‹œìŠ¤í…œë§Œ"),
        ("í…ŒìŠ¤íŠ¸", "ì‚¬ë‚´ LLM ì—°ê²° í…ŒìŠ¤íŠ¸ â†’ 1íšŒ POST ìš”ì²­"),
        ("í‰ê°€ë£¨í”„", "ê° í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤ë³„ â†’ ì‚¬ë‚´ LLM POST ìš”ì²­"),
        ("ê²°ê³¼", "JSON ì €ì¥ â†’ ë¡œì»¬ íŒŒì¼ì‹œìŠ¤í…œë§Œ")
    ]
    
    for step, description in flow_steps:
        icon = "ğŸ”’" if "ì°¨ë‹¨" in description else "ğŸ“¡" if "POST" in description else "ğŸ“"
        print(f"   {icon} {step:8} | {description}")


if __name__ == "__main__":
    print("ğŸŒ K8s Agent í‰ê°€ ì‹œìŠ¤í…œ - ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½ íë¦„ ë¶„ì„")
    print("="*70)
    
    # ì‹¤ì œ íë¦„ ì„¤ëª…
    show_actual_flow()
    
    # ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
    print(f"\nğŸ­ ì‹¤í–‰ ì‹œë®¬ë ˆì´ì…˜:")
    asyncio.run(simulate_evaluation_flow())