# K8s Agent Evaluation System (ì‚¬ë‚´ ì „ìš©)

ğŸ¢ **ì‚¬ë‚´ LLM ì„œë²„ ì „ìš©** K8s ê²€ìƒ‰ í´ëŸ¬ìŠ¤í„° ë¬¸ì˜ ì²˜ë¦¬ Agent í‰ê°€ ì‹œìŠ¤í…œ

## ğŸ”’ ë³´ì•ˆ íŠ¹ì§•

- âœ… **ì™„ì „ ë‚´ë¶€ ì²˜ë¦¬**: ëª¨ë“  ë°ì´í„°ê°€ ì‚¬ë‚´ì—ì„œë§Œ ì²˜ë¦¬
- âœ… **ì™¸ë¶€ ì „ì†¡ ì°¨ë‹¨**: LangSmith ë“± ì™¸ë¶€ ì„œë¹„ìŠ¤ ì™„ì „ ì œê±°
- âœ… **ì‚¬ë‚´ LLM ì„œë²„**: OpenAI í˜¸í™˜ API ì§€ì›
- âœ… **ë¡œì»¬ Few-shot**: YAML íŒŒì¼ ê¸°ë°˜ ì „ë¬¸ê°€ ì˜ˆì œ

## ì£¼ìš” ê¸°ëŠ¥

- **2ê°€ì§€ í‰ê°€ ë°©ì‹**: íŒŒì¼ ê¸°ë°˜ Few-shot, ìˆœìˆ˜ LLM ê¸°ë°˜
- **ë‹¤ì°¨ì› í‰ê°€**: ì •í™•ì„±, ê´€ë ¨ì„±, ì™„ì „ì„± ì ìˆ˜
- **ì¿¼ë¦¬ íƒ€ì…ë³„ ë¶„ì„**: ì˜¤ë¥˜ ë¶„ì„, ì„±ëŠ¥, êµ¬ì„±, ìŠ¤ì¼€ì¼ë§ ë“±
- **ë¡œì»¬ ì €ì¥**: ëª¨ë“  ê²°ê³¼ê°€ JSON íŒŒì¼ë¡œ ì €ì¥

## ì„¤ì¹˜

```bash
pip install -r requirements.txt

# ì‚¬ë‚´ ì „ìš© ì„¤ì • í…œí”Œë¦¿ ìƒì„±
python3 internal_llm_config.py --create-template
cp .env.internal .env
```

## ì„¤ì •

`.env` íŒŒì¼ì— ì‚¬ë‚´ LLM ì„œë²„ ì •ë³´ ì…ë ¥:

```bash
# ì‚¬ë‚´ LLM ì„œë²„ ì„¤ì •
OPENAI_API_KEY=your_internal_api_key
OPENAI_BASE_URL=http://internal-llm.company.com:8000/v1
OPENAI_MODEL=your-internal-model-name
```

## ì‚¬ìš©ë²•

```bash
# ì‚¬ë‚´ LLM ì„œë²„ë¡œ í‰ê°€ ì‹¤í–‰
python3 internal_llm_config.py
```

### í”„ë¡œê·¸ë˜ë° ë°©ì‹

```python
from src.main import K8sAgentEvaluationSystem
from src.agent.mock_agent import MockK8sAgent

# í‰ê°€ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
config = {
    "file_based_config": {
        "model": "your-internal-model",
        "few_shot_dir": "examples/few_shot_examples"
    }
}
eval_system = K8sAgentEvaluationSystem(config)

# Agent í‰ê°€
agent = MockK8sAgent(quality_level="high")
results = await eval_system.evaluate_agent(
    agent, 
    evaluator_type="file_based"  # ë˜ëŠ” "llm"
)

# ê²°ê³¼ ì¶œë ¥
eval_system.print_summary(results)
```

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
k8s-agent-evaluation/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/           # ë°ì´í„° ìŠ¤í‚¤ë§ˆ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹
â”‚   â”œâ”€â”€ evaluator/      # í‰ê°€ ëª¨ë“ˆ (íŒŒì¼ ê¸°ë°˜, LLM ê¸°ë°˜)
â”‚   â”œâ”€â”€ agent/          # Mock Agent êµ¬í˜„
â”‚   â”œâ”€â”€ metrics/        # ë©”íŠ¸ë¦­ ê³„ì‚°
â”‚   â””â”€â”€ main.py         # ë©”ì¸ ì‹¤í–‰ íŒŒì¼
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ few_shot_examples/  # ì „ë¬¸ê°€ ì˜ˆì œ YAML íŒŒì¼ë“¤
â”œâ”€â”€ internal_llm_config.py  # ì‚¬ë‚´ ì „ìš© ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ requirements.txt    # ìµœì†Œ ì˜ì¡´ì„±
```

## Few-shot ì˜ˆì œ ê´€ë¦¬

ì „ë¬¸ê°€ ì˜ˆì œë¥¼ YAML íŒŒì¼ë¡œ ê´€ë¦¬:

```yaml
# examples/few_shot_examples/error_analysis_examples.yaml
category: error_analysis
examples:
  - id: "ea_001"
    query:
      user_query: "Podê°€ CrashLoopBackOff ìƒíƒœì…ë‹ˆë‹¤."
    expert_response: |
      ì „ë¬¸ê°€ê°€ ì‘ì„±í•œ ìƒì„¸í•œ í•´ê²° ë°©ë²•...
    key_points:
      - "ì›ì¸ ë¶„ì„"
      - "í•´ê²° ë‹¨ê³„"
```

## ë³´ì•ˆ í™•ì¸ì‚¬í•­

- ğŸ”’ **LangSmith ì™„ì „ ì œê±°**: ì™¸ë¶€ ì¶”ì  ì„œë¹„ìŠ¤ ì—†ìŒ
- ğŸ”’ **ë¡œì»¬ Few-shot**: YAML íŒŒì¼ì—ì„œë§Œ ì˜ˆì œ ë¡œë“œ
- ğŸ”’ **ì‚¬ë‚´ LLMë§Œ ì‚¬ìš©**: ì™¸ë¶€ OpenAI API ì‚¬ìš© ì•ˆí•¨
- ğŸ”’ **ê²°ê³¼ ì €ì¥**: ë¡œì»¬ JSON íŒŒì¼ì—ë§Œ ì €ì¥

## ì§€ì›í•˜ëŠ” ì‚¬ë‚´ LLM ì„œë²„

OpenAI í˜¸í™˜ APIë¥¼ ì œê³µí•˜ëŠ” ëª¨ë“  ì„œë²„:
- vLLM
- Text Generation Inference (TGI)
- FastChat
- Ollama
- ì‚¬ë‚´ ì»¤ìŠ¤í…€ LLM ì„œë²„