#!/usr/bin/env python3
"""
ì‚¬ë‚´ LLM ì„œë²„ ì „ìš© ì„¤ì •
ì™„ì „ ë‚´ë¶€ ë„¤íŠ¸ì›Œí¬ì—ì„œë§Œ ë™ìž‘ (ì™¸ë¶€ ì „ì†¡ ì—†ìŒ)
"""
import os
import asyncio
import sys
from pathlib import Path
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
sys.path.append(str(Path(__file__).parent))

from src.main import K8sAgentEvaluationSystem
from src.agent.mock_agent import MockK8sAgent

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


def validate_internal_llm_config():
    """ì‚¬ë‚´ LLM ì„œë²„ ì„¤ì • ê²€ì¦"""
    print("ðŸ¢ ì‚¬ë‚´ LLM ì„œë²„ ì„¤ì • ê²€ì¦ ì¤‘...")
    
    # LangSmith ì™„ì „ ì°¨ë‹¨
    langsmith_vars = ['LANGCHAIN_API_KEY', 'LANGCHAIN_TRACING_V2', 'LANGCHAIN_PROJECT']
    blocked_count = 0
    
    for var in langsmith_vars:
        if os.getenv(var):
            os.environ.pop(var, None)
            blocked_count += 1
    
    if blocked_count > 0:
        print(f"   ðŸš« LangSmith í™˜ê²½ë³€ìˆ˜ {blocked_count}ê°œ ì°¨ë‹¨ë¨ (ì™¸ë¶€ ì „ì†¡ ë°©ì§€)")
    else:
        print(f"   âœ… ì™¸ë¶€ ì „ì†¡ ì„œë¹„ìŠ¤ ì—†ìŒ - ì•ˆì „")
    
    # ì‚¬ë‚´ LLM ì„œë²„ ì„¤ì • í™•ì¸
    base_url = os.getenv('OPENAI_BASE_URL')
    api_key = os.getenv('OPENAI_API_KEY')
    model = os.getenv('OPENAI_MODEL')
    
    print(f"\nðŸ“Š ì‚¬ë‚´ LLM ì„œë²„ ì •ë³´:")
    
    if not base_url:
        print(f"   âŒ OPENAI_BASE_URL í•„ìˆ˜")
        return False
    
    # ì‚¬ë‚´ ì„œë²„ì¸ì§€ í™•ì¸
    if 'openai.com' in base_url.lower():
        print(f"   âš ï¸  ì™¸ë¶€ OpenAI ì„œë²„ ê°ì§€: {base_url}")
        print(f"   ðŸ’¡ ì‚¬ë‚´ ì„œë²„ë¡œ ë³€ê²½í•˜ì„¸ìš” (ì˜ˆ: http://internal-llm.company.com)")
    else:
        print(f"   âœ… ì‚¬ë‚´ LLM ì„œë²„: {base_url}")
    
    if not api_key:
        print(f"   âŒ OPENAI_API_KEY í•„ìˆ˜ (ì‚¬ë‚´ ì„œë²„ ì¸ì¦)")
        return False
    else:
        print(f"   âœ… ì¸ì¦ í† í°: {api_key[:10]}... (ì‚¬ë‚´ìš©)")
    
    if not model:
        print(f"   âŒ OPENAI_MODEL í•„ìˆ˜")
        return False
    else:
        print(f"   âœ… ì‚¬ìš© ëª¨ë¸: {model}")
    
    return True


async def test_internal_llm_connection():
    """ì‚¬ë‚´ LLM ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸"""
    print(f"\nðŸ§ª ì‚¬ë‚´ LLM ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸...")
    
    try:
        from langchain.chat_models import ChatOpenAI
        
        # ì‚¬ë‚´ ì„œë²„ ì„¤ì •ìœ¼ë¡œ LLM ì´ˆê¸°í™”
        llm = ChatOpenAI(
            model=os.getenv("OPENAI_MODEL"),
            temperature=0.0,
            openai_api_key=os.getenv("OPENAI_API_KEY"),
            openai_api_base=os.getenv("OPENAI_BASE_URL")
        )
        
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
        test_message = "ì•ˆë…•í•˜ì„¸ìš”! ì‚¬ë‚´ LLM ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸ìž…ë‹ˆë‹¤."
        response = await llm.ainvoke(test_message)
        
        print(f"   âœ… ì‚¬ë‚´ LLM ì„œë²„ ì—°ê²° ì„±ê³µ!")
        print(f"   ðŸ“ ì‘ë‹µ ìƒ˜í”Œ: {response.content[:50]}...")
        return True
        
    except Exception as e:
        print(f"   âŒ ì‚¬ë‚´ ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
        print(f"   ðŸ’¡ Base URLê³¼ API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”")
        return False


async def run_fully_internal_evaluation():
    """ì™„ì „ ë‚´ë¶€ ë„¤íŠ¸ì›Œí¬ í‰ê°€ ì‹¤í–‰"""
    
    print("ðŸ¢ ì™„ì „ ë‚´ë¶€ ë„¤íŠ¸ì›Œí¬ K8s Agent í‰ê°€")
    print("ðŸ”’ ëª¨ë“  ë°ì´í„°ê°€ ì‚¬ë‚´ì—ì„œë§Œ ì²˜ë¦¬ë¨")
    print("=" * 60)
    
    if not validate_internal_llm_config():
        return
    
    # ì—°ê²° í…ŒìŠ¤íŠ¸
    if not await test_internal_llm_connection():
        return
    
    # ì™„ì „ ë‚´ë¶€ ì„¤ì •
    config = {
        "evaluator_config": {
            "model": os.getenv("OPENAI_MODEL"),
            "temperature": 0.0,
            "few_shot_dir": "examples/few_shot_examples"
        }
    }
    
    print(f"\nðŸ”’ ì™„ì „ ë‚´ë¶€ ì²˜ë¦¬ ì„¤ì •:")
    print(f"   LLM ì„œë²„: {os.getenv('OPENAI_BASE_URL')} (ì‚¬ë‚´)")
    print(f"   ëª¨ë¸: {config['evaluator_config']['model']}")
    print(f"   í‰ê°€ ë°©ì‹: LangSmith í”„ë ˆìž„ì›Œí¬ (ì™¸ë¶€ ì „ì†¡ ì°¨ë‹¨)")
    print(f"   Few-shot: ë¡œì»¬ YAML íŒŒì¼")
    print(f"   ê²°ê³¼ ì €ìž¥: ë¡œì»¬ JSONë§Œ")
    print(f"   ì™¸ë¶€ ì „ì†¡: âŒ ì™„ì „ ì°¨ë‹¨")
    
    # í‰ê°€ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    eval_system = K8sAgentEvaluationSystem(config)
    
    # í’ˆì§ˆë³„ í‰ê°€
    for quality_level in ["medium", "high"]:
        print(f"\n{'='*50}")
        print(f"ðŸ¤– {quality_level.upper()} í’ˆì§ˆ Agent í‰ê°€")
        print(f"{'='*50}")
        
        try:
            agent = MockK8sAgent(quality_level=quality_level)
            results = await eval_system.evaluate_agent(
                agent,
                sample_size=3  # ì‚¬ë‚´ ì„œë²„ ë¶€í•˜ ê³ ë ¤
            )
            
            # ê°„ë‹¨í•œ ê²°ê³¼ ì¶œë ¥
            metrics = results["metrics"]["aggregate"]["overall"]
            print(f"   ðŸ“Š ê²°ê³¼ - ì¢…í•©: {metrics['avg_overall']:.3f}")
            print(f"           ì •í™•ì„±: {metrics['avg_correctness']:.3f}")
            print(f"           ê´€ë ¨ì„±: {metrics['avg_relevance']:.3f}")
            print(f"           ì™„ì „ì„±: {metrics['avg_completeness']:.3f}")
            
            # ì‚¬ë‚´ ì „ìš© íŒŒì¼ëª…
            filename = f"internal_evaluation_{quality_level}.json"
            eval_system.save_results(results, filename)
            print(f"   ðŸ’¾ {filename} ì €ìž¥ ì™„ë£Œ")
            
        except Exception as e:
            print(f"   âŒ í‰ê°€ ì‹¤íŒ¨: {e}")
    
    print(f"\nðŸŽ‰ ì™„ì „ ë‚´ë¶€ ë„¤íŠ¸ì›Œí¬ í‰ê°€ ì™„ë£Œ!")
    print(f"\nðŸ” ë³´ì•ˆ í™•ì¸ì‚¬í•­:")
    print(f"   âœ… ëª¨ë“  LLM í˜¸ì¶œì´ ì‚¬ë‚´ ì„œë²„ë¡œë§Œ ì „ì†¡")
    print(f"   âœ… LangSmith ë“± ì™¸ë¶€ ì¶”ì  ì„œë¹„ìŠ¤ ì™„ì „ ì°¨ë‹¨") 
    print(f"   âœ… Few-shot ì˜ˆì œê°€ ë¡œì»¬ YAMLì—ì„œë§Œ ë¡œë“œ")
    print(f"   âœ… ê²°ê³¼ê°€ ë¡œì»¬ JSONì—ë§Œ ì €ìž¥")
    print(f"   âœ… ì¸í„°ë„· ì—°ê²° ì—†ì´ë„ í‰ê°€ ê°€ëŠ¥ (ì‚¬ë‚´ LLMë§Œ í•„ìš”)")


def create_internal_env_template():
    """ì‚¬ë‚´ ì „ìš© .env í…œí”Œë¦¿ ìƒì„±"""
    template = """# ì‚¬ë‚´ LLM ì„œë²„ ì „ìš© ì„¤ì •
# ì™¸ë¶€ ì„œë²„ë¡œ ë°ì´í„° ì „ì†¡ ì—†ìŒ

# ì‚¬ë‚´ LLM ì„œë²„ ì„¤ì • (í•„ìˆ˜)
OPENAI_API_KEY=your_internal_api_key_here
OPENAI_BASE_URL=http://internal-llm.company.com:8000/v1
OPENAI_MODEL=your-internal-model-name

# ì˜ˆì‹œ ì„¤ì •ë“¤:
# OPENAI_BASE_URL=http://10.0.1.100:8000/v1  # ì‚¬ë‚´ IP
# OPENAI_BASE_URL=https://llm.internal.company.com/v1  # ì‚¬ë‚´ ë„ë©”ì¸
# OPENAI_MODEL=llama-2-70b-chat  # ì‚¬ë‚´ ëª¨ë¸ëª…
# OPENAI_MODEL=gpt-4-company-fine-tuned  # ì‚¬ë‚´ íŒŒì¸íŠœë‹ ëª¨ë¸

# âš ï¸ ì ˆëŒ€ ì„¤ì •í•˜ì§€ ë§ˆì„¸ìš” (ì™¸ë¶€ ì „ì†¡ë¨):
# LANGCHAIN_API_KEY=...
# LANGCHAIN_TRACING_V2=true
# LANGCHAIN_PROJECT=...
"""
    
    with open(".env.internal", "w") as f:
        f.write(template)
    
    print(f"ðŸ“ ì‚¬ë‚´ ì „ìš© ì„¤ì • í…œí”Œë¦¿ ìƒì„±: .env.internal")
    print(f"   cp .env.internal .env í›„ ì‹¤ì œ ê°’ìœ¼ë¡œ ìˆ˜ì •í•˜ì„¸ìš”")


if __name__ == "__main__":
    if len(sys.argv) > 1 and sys.argv[1] == "--create-template":
        create_internal_env_template()
    else:
        asyncio.run(run_fully_internal_evaluation())