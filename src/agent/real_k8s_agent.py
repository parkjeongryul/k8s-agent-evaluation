"""
ì‹¤ì œ K8s Agent ì˜ˆì‹œ - ì‚¬ë‚´ LLMì„ ì‚¬ìš©í•˜ëŠ” ì§„ì§œ Agent
"""
import asyncio
from typing import Dict, Any
from uuid import uuid4
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from ..data.schemas import K8sQuery, AgentResponse


class RealK8sAgent:
    """ì‹¤ì œ K8s ë¬¸ì˜ ì²˜ë¦¬ Agent - ì‚¬ë‚´ LLM ì‚¬ìš©"""
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}
        
        # ì‚¬ë‚´ LLM ì´ˆê¸°í™”
        self.llm = ChatOpenAI(
            model=self.config.get("model", "gpt-4"),
            temperature=self.config.get("temperature", 0.7)
        )
        
        # K8s ì „ë¬¸ê°€ í”„ë¡¬í”„íŠ¸
        self.prompt = ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ K8s ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
            ì‚¬ìš©ìì˜ K8s ê´€ë ¨ ë¬¸ì˜ì— ëŒ€í•´ ì •í™•í•˜ê³  ì‹¤ìš©ì ì¸ í•´ê²°ì±…ì„ ì œì‹œí•˜ì„¸ìš”.
            
            ì‘ë‹µ ì‹œ ë‹¤ìŒì„ í¬í•¨í•˜ì„¸ìš”:
            1. ë¬¸ì œ ì›ì¸ ë¶„ì„
            2. ë‹¨ê³„ë³„ í•´ê²° ë°©ë²•
            3. ì˜ˆë°© ì¡°ì¹˜
            4. ê´€ë ¨ kubectl ëª…ë ¹ì–´"""),
            
            ("human", """ì¿¼ë¦¬ íƒ€ì…: {query_type}
            ë¬¸ì˜ ë‚´ìš©: {user_query}
            
            ì»¨í…ìŠ¤íŠ¸ ì •ë³´:
            {context}
            
            ìœ„ K8s ë¬¸ì œì— ëŒ€í•œ í•´ê²°ì±…ì„ ì œì‹œí•´ì£¼ì„¸ìš”.""")
        ])
        
    async def process_query(self, query: K8sQuery) -> AgentResponse:
        """ì‹¤ì œ LLMì„ ì‚¬ìš©í•´ K8s ë¬¸ì˜ ì²˜ë¦¬"""
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt_value = self.prompt.format_prompt(
            query_type=query.query_type if isinstance(query.query_type, str) else query.query_type.value,
            user_query=query.user_query,
            context=str(query.context)
        )
        
        # ì‚¬ë‚´ LLM í˜¸ì¶œ
        start_time = asyncio.get_event_loop().time()
        llm_response = await self.llm.ainvoke(prompt_value.to_messages())
        execution_time = asyncio.get_event_loop().time() - start_time
        
        # ì‹ ë¢°ë„ ê³„ì‚° (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë¡œì§ í•„ìš”)
        confidence_score = self._calculate_confidence(llm_response.content)
        
        # ì†ŒìŠ¤ ìƒì„±
        sources = self._generate_sources(query.query_type)
        
        return AgentResponse(
            response_id=str(uuid4()),
            query_id=query.query_id,
            answer=llm_response.content,
            reasoning=f"ì‚¬ë‚´ LLMì„ í†µí•œ ì‹¤ì‹œê°„ ë¶„ì„",
            confidence_score=confidence_score,
            sources=sources,
            execution_time=execution_time
        )
    
    def _calculate_confidence(self, response: str) -> float:
        """ì‘ë‹µ ì‹ ë¢°ë„ ê³„ì‚° (ê°„ë‹¨í•œ ì˜ˆì‹œ)"""
        # ì‹¤ì œë¡œëŠ” ì‘ë‹µ ê¸¸ì´, êµ¬ì²´ì„±, í‚¤ì›Œë“œ ë“±ì„ ë¶„ì„
        if len(response) > 500 and "kubectl" in response:
            return 0.9
        elif len(response) > 200:
            return 0.7
        else:
            return 0.5
    
    def _generate_sources(self, query_type) -> list:
        """ì°¸ê³  ì†ŒìŠ¤ ìƒì„±"""
        base_sources = [
            "Kubernetes Official Documentation",
            "ì‚¬ë‚´ K8s ìš´ì˜ ê°€ì´ë“œ"
        ]
        
        type_specific = {
            "error_analysis": ["K8s ì—ëŸ¬ ì½”ë“œ ì°¸ì¡°", "ì‚¬ë‚´ ì¥ì•  ëŒ€ì‘ ë§¤ë‰´ì–¼"],
            "performance": ["K8s ì„±ëŠ¥ ìµœì í™” ê°€ì´ë“œ", "ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ"],
            "configuration": ["K8s ë¦¬ì†ŒìŠ¤ ìŠ¤í™", "ì‚¬ë‚´ ì„¤ì • í…œí”Œë¦¿"]
        }
        
        query_type_str = query_type if isinstance(query_type, str) else query_type.value
        return base_sources + type_specific.get(query_type_str, [])


# ì‚¬ìš© ì˜ˆì‹œ
async def compare_agents():
    """Mock vs Real Agent ë¹„êµ"""
    from .mock_agent import MockK8sAgent
    
    query = K8sQuery(
        query_id="test_001",
        user_query="Podê°€ OOMKilled ì—ëŸ¬ë¡œ ì¬ì‹œì‘ë©ë‹ˆë‹¤. ì–´ë–»ê²Œ í•´ê²°í•˜ë‚˜ìš”?",
        query_type="error_analysis",
        context={"error": "OOMKilled", "namespace": "production"}
    )
    
    print("ğŸ¤– Mock Agent (í…œí”Œë¦¿ ê¸°ë°˜):")
    mock_agent = MockK8sAgent(quality_level="high")
    mock_response = await mock_agent.process_query(query)
    print(f"ì‘ë‹µ: {mock_response.answer[:100]}...")
    print(f"LLM í˜¸ì¶œ: âŒ ì—†ìŒ (í…œí”Œë¦¿ë§Œ ì‚¬ìš©)")
    
    print("\nğŸ¤– Real Agent (ì‚¬ë‚´ LLM ì‚¬ìš©):")
    real_agent = RealK8sAgent()
    real_response = await real_agent.process_query(query)
    print(f"ì‘ë‹µ: {real_response.answer[:100]}...")
    print(f"LLM í˜¸ì¶œ: âœ… ì‚¬ë‚´ ì„œë²„ 1íšŒ")
    print(f"ì‹¤í–‰ ì‹œê°„: {real_response.execution_time:.2f}ì´ˆ")